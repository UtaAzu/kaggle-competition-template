# ç”»åƒã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ãƒ»è‡ªå·±å®Œçµå‹ãƒ»è¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä½œæˆã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ï¼ˆæ±ç”¨ç‰ˆï¼šãƒ”ã‚¯ã‚»ãƒ«/ç‰¹å¾´é‡ä¸¡å¯¾å¿œï¼‰

---

## ç›®çš„ãƒ»å‰æ

- Kaggle/ãƒ­ãƒ¼ã‚«ãƒ«ä¸¡å¯¾å¿œã®ã€Œè‡ªå·±å®Œçµå‹ã€å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½œæˆã™ã‚‹
- **è¤‡æ•°foldï¼ˆCVï¼‰æ™‚ã¯ã€Œfoldã”ã¨æˆæœç‰©ã€ã¨ã€Œå…¨ä½“é›†è¨ˆæˆæœç‰©ï¼ˆoverall_metrics.jsonç­‰ï¼‰ã€ã®ä¸¡æ–¹ã‚’å¿…ãšç”Ÿæˆãƒ»ä¿å­˜ã™ã‚‹ã“ã¨**
- æˆæœç‰©ã¯ä»¥ä¸‹ã®å ´æ‰€ã«ä¿å­˜ã™ã‚‹ï¼ˆä¸Šä½ã«ä½™è¨ˆãª `<EXP_ID>` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œã‚‰ãªã„ï¼‰
    - ãƒ­ãƒ¼ã‚«ãƒ«: `experiments/<exp_id>-artifacts/`
    - Kaggle: `/kaggle/working/<exp_id>-artifacts/`
    - foldã”ã¨ã¯ `fold0/`, `fold1/`, ...ã€å…¨ä½“é›†è¨ˆã¯ `*-artifacts/` ç›´ä¸‹ã«é…ç½®
- validate.pyã‚„æ¤œè¨¼Notebookã§å…¨ä½“é›†è¨ˆæˆæœç‰©ã‚’è‡ªå‹•ç”Ÿæˆãƒ»ç¢ºèªã™ã‚‹

---

## 0. ğŸ·ï¸ ãƒ¡ã‚¿æƒ…å ±ãƒ–ãƒ­ãƒƒã‚¯ (Meta Information Block)

- å®Ÿé¨“ç•ªå·ã€ã‚¿ã‚¤ãƒˆãƒ«ã€ç›®çš„ã€æ—¥ä»˜ã€è‘—è€…ã€æ¦‚è¦ã‚’æœ€ä¸Šéƒ¨ã«æ˜è¨˜
- ä¾‹ï¼ˆæ±ç”¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼‰

```python
# === EXPXXX_vY: [å®Ÿé¨“ã®ç›®çš„ã‚’ç°¡æ½”ã«æ›¸ã] ===
# Date: 2025-XX-XX
# Author: UtaAzu
# Purpose: [ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³/å½é€ æ¤œå‡º/ãã®ä»–ã®ç›®çš„]
# Strategy: [pixel_based | feature_based]
# Dataset: [ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå]
# Expected Outcome: [æœŸå¾…ã™ã‚‹CV/LBç›®æ¨™]
# Notes: [ç‰¹è¨˜äº‹é …]
```

---

## 1. ğŸ“ è¨­å®šãƒ–ãƒ­ãƒƒã‚¯ (Configuration Block) â€” æˆ¦ç•¥ãƒ‡ã‚¹ã‚¯

- **æœ€ä¸Šä½æˆ¦ç•¥ãƒ•ãƒ©ã‚° `TRAINING_MODE`** ã§å­¦ç¿’æ–¹å¼ã‚’åˆ‡ã‚Šæ›¿ãˆ
- **ãƒ”ã‚¯ã‚»ãƒ«ãƒ™ãƒ¼ã‚¹ï¼ˆ`pixel_based`ï¼‰**: ç”»åƒã‚’ç›´æ¥å…¥åŠ›ï¼ˆU-Net, SMPç­‰ï¼‰
- **ç‰¹å¾´é‡ãƒ™ãƒ¼ã‚¹ï¼ˆ`feature_based`ï¼‰**: äº‹å‰æŠ½å‡ºç‰¹å¾´é‡ã‚’å…¥åŠ›ï¼ˆDINOv2ç­‰ï¼‰
- **æ¨™æº–å…µå™¨ï¼ˆã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å¯¾ç­–ï¼‰ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆON**

```python
from pathlib import Path
from datetime import datetime
import torch

class Config:
    EXP_ID = "EXPXXX_vY"
    DESCRIPTION = "[å®Ÿé¨“ã®ç›®çš„ã‚’ç°¡æ½”ã«]"
    DATE = datetime.now().strftime('%Y-%m-%d')

    # === æœ€ä¸Šä½æˆ¦ç•¥ãƒ•ãƒ©ã‚° ===
    # "pixel_based": ç”»åƒã‚’ç›´æ¥å…¥åŠ›ï¼ˆU-Net, SMPç­‰ï¼‰
    # "feature_based": äº‹å‰æŠ½å‡ºã—ãŸç‰¹å¾´é‡ã‚’å…¥åŠ›ï¼ˆDINOv2ç‰¹å¾´é‡ç­‰ï¼‰
    TRAINING_MODE = "feature_based"  # or "pixel_based"

    # === ãƒ”ã‚¯ã‚»ãƒ«ãƒ™ãƒ¼ã‚¹å­¦ç¿’ç”¨ã®è¨­å®š ===
    class PixelConfig:
        BACKBONE = "efficientnet-b0"  # or "resnet34", "mobilenet_v3_small"
        MODEL_TYPE = "smp.Unet"  # "smp.Unet", "FastUNet", "custom_cnn"
        IMAGE_SIZE = 384
        AUGMENTATIONS = "medium"  # "light", "medium", "heavy", "none"

    # === ç‰¹å¾´é‡ãƒ™ãƒ¼ã‚¹å­¦ç¿’ç”¨ã®è¨­å®š ===
    class FeatureConfig:
        ENCODER_ID = "dino_v2_base"  # ç‰¹å¾´é‡ã‚»ãƒƒãƒˆã®IDï¼ˆè¨˜éŒ²ç”¨ï¼‰
        FEATURE_DIR = Path('/kaggle/input/exp003t-dino-v2-features') if Path('/kaggle/input').exists() else Path('./features/exp003t-dino-v2')
        FEATURE_DIM = 768  # DINOv2 small:384, base:768, large:1024
        FEATURE_SUFFIX = ".npy"  # ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­
        DECODER_TYPE = "SimpleDecoder"  # "SimpleDecoder", "LightUNetDecoder", "ConvHead"

    # === å…¨ãƒ¢ãƒ¼ãƒ‰å…±é€šã®å­¦ç¿’è¨­å®š ===
    class TrainConfig:
        NUM_EPOCHS = 10
        BATCH_SIZE = 16
        LEARNING_RATE = 1e-3
        WEIGHT_DECAY = 1e-4

        # --- æ¨™æº–å…µå™¨ï¼šã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å¯¾ç­–ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆONï¼‰ ---
        USE_WEIGHTED_SAMPLER = True
        FORGED_SAMPLE_WEIGHT = 3.0  # forgedç”»åƒã‚’ä½•å€é‡è¦–ã™ã‚‹ã‹

        USE_WEIGHTED_LOSS = True
        POS_WEIGHT = 20.0  # ä¸æ­£ãƒ”ã‚¯ã‚»ãƒ«ã¸ã®ãƒšãƒŠãƒ«ãƒ†ã‚£å€ç‡

    # === ç’°å¢ƒè‡ªå‹•åˆ‡æ›¿ ===
    IS_KAGGLE = Path('/kaggle/input').exists()
    if IS_KAGGLE:
        base = Path('/kaggle/input')
        candidates = [d for d in base.iterdir() if d.is_dir()]
        DATA_DIR = candidates[0] if candidates else base
        ARTIFACTS_ROOT = Path('/kaggle/working')
        DEBUG = False
    else:
        DATA_DIR = Path('./')
        ARTIFACTS_ROOT = Path('experiments')
        DEBUG = True

    # === Paths ===
    AUTHENTIC_DIR = DATA_DIR / 'train_images' / 'authentic'
    FORGED_DIR = DATA_DIR / 'train_images' / 'forged'
    MASKS_DIR = DATA_DIR / 'train_masks'
    TEST_DIR = DATA_DIR / 'test_images'
    SAMPLE_SUBMISSION_PATH = DATA_DIR / 'sample_submission.csv'

    # === CV ===
    N_SPLITS = 5
    GROUP_COL = 'case_id'
    USE_FIRST_FOLD_ONLY = True
    RANDOM_STATE = 42

    # === Post-processingï¼ˆã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒå¯¾è±¡ï¼‰ ===
    CONFIDENCE_THRESHOLDS_GRID = [0.15, 0.30, 0.50, 0.70]
    MIN_AREA_GRID = [10, 25, 50, 100]
    MORPH_KERNEL_SIZE_GRID = [0, 3, 5]

    # === é€€åŒ–è§£ã‚¬ãƒ¼ãƒ‰ï¼ˆå¼·åˆ¶åœæ­¢é–¾å€¤ï¼‰ ===
    MIN_FORGED_NONEMPTY_RATIO = 0.20
    MAX_AUTHENTIC_FP_RATIO = 0.30

    # === Fallbackï¼ˆæ¨è«–ã§ç©ºãªã‚‰ç·©å’Œå†è©¦è¡Œï¼‰ ===
    FALLBACK_ON_EMPTY = True
    FALLBACK_MASK_TH = 0.20
    FALLBACK_MIN_AREA = 10
    FALLBACK_MORPH_KERNEL = 0

    # === Device ===
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # === Artifacts ===
    ARTIFACTS_DIR = ARTIFACTS_ROOT / f'{EXP_ID.lower().replace("_", "-")}-artifacts'
    ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)
    MODELS_DIR = ARTIFACTS_DIR / 'models'
    MODELS_DIR.mkdir(parents=True, exist_ok=True)
    OUTPUT_DIR = ARTIFACTS_DIR  # äº’æ›: æ—¢å­˜ã‚³ãƒ¼ãƒ‰ãŒOUTPUT_DIRã‚’å‚ç…§ã™ã‚‹å ´åˆã«å‚™ãˆã‚‹
```

---

## 2. â±ï¸ ãƒ­ã‚®ãƒ³ã‚°ãƒ–ãƒ­ãƒƒã‚¯ (Logging Block)

- ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ï¼‹ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
- ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ï¼ˆä¸»è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼‰ã‚’è¨˜éŒ²

```python
import sys

class Logger:
    def __init__(self, log_path: Path):
        self.log_path = log_path
        self.log_path.parent.mkdir(parents=True, exist_ok=True)
        self.info("=== Environment Information ===")
        self.info(f"Python: {sys.version}")
        self.info(f"PyTorch: {torch.__version__}")
        self.info(f"Device: {Config.DEVICE}")
        self.info("=" * 50)
        for lib in ['torch', 'numpy', 'pandas', 'opencv-python']:
            try:
                if lib == 'opencv-python':
                    import cv2
                    self.info(f"opencv: {cv2.__version__}")
                else:
                    self.info(f"{lib}: {__import__(lib).__version__}")
            except Exception:
                self.info(f"{lib}: n/a")

    def info(self, message: str):
        ts = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        line = f"[{ts}] {message}"
        print(line)
        with open(self.log_path, 'a', encoding='utf-8') as f:
            f.write(line + '\n')
```

---

## 3. ğŸ”§ ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ–ãƒ­ãƒƒã‚¯ (Data Processing Block) â€” èª¿ç†å ´

- **`TRAINING_MODE`ã«å¿œã˜ã¦é©åˆ‡ãªDatasetã‚’è¿”ã™ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼**ã‚’å°å…¥
- ãƒ”ã‚¯ã‚»ãƒ«ãƒ™ãƒ¼ã‚¹: `PixelDataset`
- ç‰¹å¾´é‡ãƒ™ãƒ¼ã‚¹: `FeatureDataset`

```python
import pandas as pd
import numpy as np
import cv2
from torch.utils.data import Dataset

def prepare_dataframe(config: Config) -> pd.DataFrame:
    """
    ç”»åƒãƒ‘ã‚¹ã¨ãƒã‚¹ã‚¯ãƒ‘ã‚¹ã‚’å«ã‚€DataFrameã‚’ä½œæˆ
    """
    rows = []
    # authentic
    for p in sorted(config.AUTHENTIC_DIR.glob('*.png')):
        image_id = p.stem
        case_id = image_id.split('_')[0]
        rows.append({
            'image_id': image_id,
            'case_id': case_id,
            'is_forged': 0,
            'image_path': str(p),
            'mask_path': None
        })
    # forged
    for p in sorted(config.FORGED_DIR.glob('*.png')):
        image_id = p.stem
        case_id = image_id.split('_')[0]
        mask_path = config.MASKS_DIR / f"{image_id}.npy"
        rows.append({
            'image_id': image_id,
            'case_id': case_id,
            'is_forged': 1,
            'image_path': str(p),
            'mask_path': str(mask_path) if mask_path.exists() else None
        })
    return pd.DataFrame(rows)

# === PixelDatasetï¼ˆç”»åƒã‹ã‚‰å­¦ç¿’ï¼‰ ===
class PixelDataset(Dataset):
    def __init__(self, df: pd.DataFrame, config: Config.PixelConfig, transforms=None):
        self.df = df.reset_index(drop=True)
        self.img_size = config.IMAGE_SIZE
        self.transforms = transforms

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx: int):
        row = self.df.iloc[idx]
        img = cv2.imread(row['image_path'])
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, (self.img_size, self.img_size))

        if pd.notna(row['mask_path']) and Path(row['mask_path']).exists():
            mask = np.load(row['mask_path']).astype(np.uint8)
            if mask.ndim == 3:
                mask = mask.max(axis=0)
            mask = cv2.resize(mask, (self.img_size, self.img_size), interpolation=cv2.INTER_NEAREST)
            mask = (mask > 0).astype(np.float32)
        else:
            mask = np.zeros((self.img_size, self.img_size), dtype=np.float32)

        if self.transforms:
            augmented = self.transforms(image=img, mask=mask)
            img, mask = augmented['image'], augmented['mask']

        img = torch.from_numpy(img.astype(np.float32) / 255.0).permute(2, 0, 1)
        mask = torch.from_numpy(mask).unsqueeze(0)
        return img, mask, idx

# === FeatureDatasetï¼ˆç‰¹å¾´é‡ã‹ã‚‰å­¦ç¿’ï¼‰ ===
class FeatureDataset(Dataset):
    def __init__(self, df: pd.DataFrame, config: Config.FeatureConfig):
        self.df = df.reset_index(drop=True)
        self.feature_dir = config.FEATURE_DIR
        self.feature_dim = config.FEATURE_DIM

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx: int):
        row = self.df.iloc[idx]
        # ç‰¹å¾´é‡èª­ã¿è¾¼ã¿ï¼ˆtrain_features/{authentic|forged}/{image_id}.npyæƒ³å®šï¼‰
        label = 'forged' if row['is_forged'] == 1 else 'authentic'
        feat_path = self.feature_dir / 'train_features' / label / f"{row['image_id']}.npy"
        feat = np.load(feat_path).astype(np.float32)
        if feat.ndim == 3 and feat.shape[0] != self.feature_dim and feat.shape[-1] == self.feature_dim:
            feat = feat.transpose(2, 0, 1)  # (H,W,C)->(C,H,W)
        feat_t = torch.from_numpy(feat)

        # GT mask
        if pd.notna(row['mask_path']) and Path(row['mask_path']).exists():
            mask = np.load(row['mask_path']).astype(np.uint8)
            if mask.ndim == 3:
                mask = mask.max(axis=0)
            _, H, W = feat_t.shape
            mask = cv2.resize(mask, (W, H), interpolation=cv2.INTER_NEAREST)
            mask = (mask > 0).astype(np.float32)
        else:
            _, H, W = feat_t.shape
            mask = np.zeros((H, W), dtype=np.float32)
        mask_t = torch.from_numpy(mask).unsqueeze(0)

        return feat_t, mask_t, idx

# === Datasetã‚’ç”Ÿæˆã™ã‚‹ã€Œå·¥å ´ã€ ===
def get_dataset(df: pd.DataFrame, config: Config, is_train: bool):
    if config.TRAINING_MODE == "pixel_based":
        transforms = get_augmentations(config.PixelConfig.AUGMENTATIONS) if is_train else None
        return PixelDataset(df, config.PixelConfig, transforms=transforms)
    elif config.TRAINING_MODE == "feature_based":
        return FeatureDataset(df, config.FeatureConfig)
    else:
        raise ValueError(f"Unknown TRAINING_MODE: {config.TRAINING_MODE}")

def get_augmentations(level: str):
    """Augmentationãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸå¤‰æ›ï¼ˆalbumentationsä½¿ç”¨æƒ³å®šï¼‰"""
    # å®Ÿè£…ä¾‹ï¼ˆalbumentationsçœç•¥æ™‚ã¯Noneã‚’è¿”ã™ï¼‰
    if level == "none":
        return None
    # elif level == "light": return A.Compose([A.HorizontalFlip(p=0.5)])
    # elif level == "medium": return A.Compose([...])
    # elif level == "heavy": return A.Compose([...])
    return None
```

---

## 4. ğŸ¤– ãƒ¢ãƒ‡ãƒ«å®šç¾©ãƒ–ãƒ­ãƒƒã‚¯ (Model Definition Block) â€” ä¿³å„ªäº‹å‹™æ‰€

- **`TRAINING_MODE`ã¨ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦é©åˆ‡ãªãƒ¢ãƒ‡ãƒ«ã‚’è¿”ã™ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼**ã‚’å°å…¥

```python
import torch.nn as nn

# === SimpleDecoderï¼ˆç‰¹å¾´é‡ãƒ™ãƒ¼ã‚¹ç”¨ï¼‰ ===
class SimpleDecoder(nn.Module):
    def __init__(self, in_channels: int = 768, mid_channels: int = 256):
        super().__init__()
        self.head = nn.Sequential(
            nn.Conv2d(in_channels, mid_channels, 1),
            nn.BatchNorm2d(mid_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(mid_channels, mid_channels, 3, padding=1),
            nn.BatchNorm2d(mid_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(mid_channels, 1, 1)
        )

    def forward(self, x):
        return torch.sigmoid(self.head(x))

# === FastUNetï¼ˆãƒ”ã‚¯ã‚»ãƒ«ãƒ™ãƒ¼ã‚¹ç”¨ãƒ»è»½é‡ï¼‰ ===
class FastUNet(nn.Module):
    def __init__(self, in_channels=3, out_channels=1):
        super().__init__()
        self.enc1 = self.conv_block(in_channels, 32)
        self.enc2 = self.conv_block(32, 64)
        self.enc3 = self.conv_block(64, 128)
        self.bottleneck = self.conv_block(128, 256)
        self.up3 = nn.ConvTranspose2d(256, 128, 2, 2)
        self.dec3 = self.conv_block(256, 128)
        self.up2 = nn.ConvTranspose2d(128, 64, 2, 2)
        self.dec2 = self.conv_block(128, 64)
        self.up1 = nn.ConvTranspose2d(64, 32, 2, 2)
        self.dec1 = self.conv_block(64, 32)
        self.out = nn.Conv2d(32, out_channels, 1)
        self.pool = nn.MaxPool2d(2, 2)

    def conv_block(self, in_ch, out_ch):
        return nn.Sequential(
            nn.Conv2d(in_ch, out_ch, 3, padding=1),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_ch, out_ch, 3, padding=1),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        e1 = self.enc1(x)
        e2 = self.enc2(self.pool(e1))
        e3 = self.enc3(self.pool(e2))
        b = self.bottleneck(self.pool(e3))
        d3 = self.up3(b)
        d3 = torch.cat([d3, e3], dim=1)
        d3 = self.dec3(d3)
        d2 = self.up2(d3)
        d2 = torch.cat([d2, e2], dim=1)
        d2 = self.dec2(d2)
        d1 = self.up1(d2)
        d1 = torch.cat([d1, e1], dim=1)
        d1 = self.dec1(d1)
        return torch.sigmoid(self.out(d1))

# === ãƒ¢ãƒ‡ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã€Œä¿³å„ªäº‹å‹™æ‰€ã€ ===
def build_model(config: Config):
    if config.TRAINING_MODE == "pixel_based":
        if config.PixelConfig.MODEL_TYPE == "FastUNet":
            return FastUNet(in_channels=3, out_channels=1).to(config.DEVICE)
        # elif config.PixelConfig.MODEL_TYPE == "smp.Unet":
        #     import segmentation_models_pytorch as smp
        #     return smp.Unet(encoder_name=config.PixelConfig.BACKBONE, ...).to(config.DEVICE)
        else:
            raise ValueError(f"Unknown MODEL_TYPE: {config.PixelConfig.MODEL_TYPE}")

    elif config.TRAINING_MODE == "feature_based":
        if config.FeatureConfig.DECODER_TYPE == "SimpleDecoder":
            return SimpleDecoder(in_channels=config.FeatureConfig.FEATURE_DIM).to(config.DEVICE)
        # elif config.FeatureConfig.DECODER_TYPE == "LightUNetDecoder":
        #     return LightUNetDecoder(...).to(config.DEVICE)
        else:
            raise ValueError(f"Unknown DECODER_TYPE: {config.FeatureConfig.DECODER_TYPE}")

    else:
        raise ValueError(f"Unknown TRAINING_MODE: {config.TRAINING_MODE}")
```

---

## 5. ğŸ“ å­¦ç¿’ãƒ»è©•ä¾¡é–¢æ•°ãƒ–ãƒ­ãƒƒã‚¯ (Training & Evaluation)

- **æ¨™æº–å…µå™¨ï¼ˆWeightedBCEDiceLossï¼‰ã‚’æ¨™æº–å®Ÿè£…**
- train_epochã¯å¾“æ¥é€šã‚Šï¼ˆBCE/Diceç­‰ï¼‰
- validateã¯oOF1ãƒ™ãƒ¼ã‚¹ã®validate_gridã‚’æ¡ç”¨

```python
from tqdm import tqdm

# === æ¨™æº–å…µå™¨ï¼šWeightedBCEDiceLoss ===
class WeightedBCEDiceLoss(nn.Module):
    def __init__(self, pos_weight: float = 1.0, bce_weight: float = 0.5, dice_weight: float = 0.5, smooth: float = 1.0):
        super().__init__()
        self.bce = nn.BCELoss(reduction='none')
        self.bce_weight = bce_weight
        self.dice_weight = dice_weight
        self.smooth = smooth
        self.pos_weight = pos_weight

    def forward(self, pred, target):
        # Weighted BCE
        bce_loss = self.bce(pred, target)
        weight_map = torch.where(target > 0.5, self.pos_weight, 1.0)
        bce_loss = (bce_loss * weight_map).mean()

        # Dice
        intersection = (pred * target).sum(dim=(2, 3))
        union = pred.sum(dim=(2, 3)) + target.sum(dim=(2, 3))
        dice = (2 * intersection + self.smooth) / (union + self.smooth)
        dice_loss = 1 - dice.mean()

        return self.bce_weight * bce_loss + self.dice_weight * dice_loss

def train_epoch(model, loader, optimizer, criterion, device):
    model.train()
    total = 0.0
    for feats, masks, _ in tqdm(loader, desc="Training"):
        feats, masks = feats.to(device), masks.to(device)
        optimizer.zero_grad()
        pred = model(feats)
        loss = criterion(pred, masks)
        loss.backward()
        optimizer.step()
        total += loss.item()
    return total / len(loader)

def mask_f1_binary(pred: np.ndarray, gt: np.ndarray) -> float:
    pred = pred.astype(bool).ravel()
    gt = gt.astype(bool).ravel()
    tp = np.logical_and(pred, gt).sum()
    fp = np.logical_and(pred, np.logical_not(gt)).sum()
    fn = np.logical_and(np.logical_not(pred), gt).sum()
    if tp + fp + fn == 0:
        return 1.0
    return float(2.0 * tp / (2.0 * tp + fp + fn + 1e-9))

def validate_grid(model, loader, thresholds, min_area_grid, morph_kernel_grid, device, ref_df):
    model.eval()
    best_cfg, best_mean_f1 = None, -1.0
    results = []
    with torch.no_grad():
        for min_area in min_area_grid:
            for morph_k in morph_kernel_grid:
                rows = []
                agg = {float(t): [] for t in thresholds}
                forged_nonempty, authentic_nonempty = [], []
                for feats, masks_gt, idxs in tqdm(loader, desc=f"OOF area={min_area}, kernel={morph_k}"):
                    feats = feats.to(device)
                    probs = model(feats).cpu().numpy()
                    masks_gt_np = masks_gt.numpy()
                    for i, idx in enumerate(idxs):
                        prob = probs[i, 0]
                        gt = masks_gt_np[i, 0]
                        rec = ref_df.iloc[idx.item()]
                        per_t = {}
                        best_t, best_f1, best_bin = None, -1, None
                        for t in thresholds:
                            pred_bin = (prob > float(t)).astype(np.uint8)
                            if morph_k > 0:
                                kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (morph_k, morph_k))
                                pred_bin = cv2.morphologyEx(pred_bin, cv2.MORPH_CLOSE, kernel)
                                pred_bin = cv2.morphologyEx(pred_bin, cv2.MORPH_OPEN, kernel)
                            num_labels, labels = cv2.connectedComponents(pred_bin)
                            pred_filtered = np.zeros_like(pred_bin)
                            for lbl in range(1, num_labels):
                                if np.sum(labels == lbl) >= min_area:
                                    pred_filtered[labels == lbl] = 1
                            f1 = mask_f1_binary(pred_filtered, gt)
                            per_t[float(t)] = f1
                            agg[float(t)].append(f1)
                            if f1 > best_f1:
                                best_f1, best_t, best_bin = f1, float(t), pred_filtered
                        nonempty = int(best_bin.sum() > 0)
                        if int(rec["is_forged"]) == 1:
                            forged_nonempty.append(nonempty)
                        else:
                            authentic_nonempty.append(nonempty)
                        rows.append({
                            "case_id": rec["case_id"], "image_id": rec["image_id"], "is_forged": int(rec["is_forged"]),
                            "min_area": min_area, "morph_kernel": morph_k, "best_threshold": best_t,
                            "best_f1": best_f1, "pred_nonempty": nonempty,
                            **{f"f1@{t}": per_t[float(t)] for t in thresholds}
                        })
                th2mean = {float(t): float(np.mean(agg[float(t)])) if len(agg[float(t)]) else 0.0 for t in thresholds}
                mean_f1 = max(th2mean.values())
                forged_nonempty_ratio = float(np.mean(forged_nonempty)) if len(forged_nonempty) else 0.0
                authentic_nonempty_ratio = float(np.mean(authentic_nonempty)) if len(authentic_nonempty) else 0.0
                results.append((min_area, morph_k, mean_f1, th2mean, rows, {
                    "forged_nonempty_ratio": forged_nonempty_ratio,
                    "authentic_nonempty_ratio": authentic_nonempty_ratio,
                }))
                if forged_nonempty_ratio >= 0.05 and mean_f1 > best_mean_f1:
                    best_mean_f1 = mean_f1
                    best_cfg = (min_area, morph_k, th2mean, rows)
    return best_cfg, results
```

---

## 6. ğŸ’¾ æˆæœç‰©ä¿å­˜ãƒ–ãƒ­ãƒƒã‚¯ (Artifact Saving Block)ï¼‹å¼·åˆ¶åœæ­¢

- metrics.json/run.jsonã¸macro_f1, forged_nonempty_ratio, authentic_fp_ratioã‚’è¨˜éŒ²
- åˆ†é›¢æŒ‡æ¨™ãŒä¸å¥å…¨ãªã‚‰SystemExit(1)ã§å¼·åˆ¶åœæ­¢

- **foldã”ã¨ã« `fold{n}/metrics.json`, `fold{n}/oof.csv` ãªã©ã‚’ä¿å­˜**
- **å…¨foldçµ‚äº†å¾Œã€`overall_metrics.json`, `oof_all.csv`, `validate_summary.csv` ãªã©å…¨ä½“é›†è¨ˆæˆæœç‰©ã‚’ `*-artifacts/` ç›´ä¸‹ã«å¿…ãšç”Ÿæˆãƒ»ä¿å­˜ã™ã‚‹ã“ã¨**
- validate.pyã‚„æ¤œè¨¼Notebookã§å…¨ä½“é›†è¨ˆæˆæœç‰©ã‚’è‡ªå‹•ç”Ÿæˆãƒ»ç¢ºèªã™ã‚‹

```python
import json

def save_validation_artifacts(oof_rows, th2mean, out_dir, exp_id, best_min_area, best_morph_k, config: Config):
    # foldãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å¿…ãšä½œæˆã—ã¦ã‹ã‚‰ä¿å­˜
    out_dir.mkdir(parents=True, exist_ok=True)
    oof_df = pd.DataFrame(oof_rows)
    oof_df.to_csv(out_dir / "oof.csv", index=False)

    best_t = max(th2mean, key=th2mean.get)
    zero_f1_ratio = float((oof_df["best_f1"] == 0.0).mean()) if len(oof_df) else 0.0
    perfect_f1_ratio = float((oof_df["best_f1"] == 1.0).mean()) if len(oof_df) else 0.0

    authentic_df = oof_df[oof_df["is_forged"] == 0]
    forged_df = oof_df[oof_df["is_forged"] == 1]
    authentic_f1_mean = float(authentic_df["best_f1"].mean()) if len(authentic_df) else 0.0
    forged_f1_mean = float(forged_df["best_f1"].mean()) if len(forged_df) else 0.0
    forged_nonempty_ratio = float(forged_df["pred_nonempty"].mean()) if len(forged_df) else 0.0
    authentic_fp_ratio = float(authentic_df["pred_nonempty"].mean()) if len(authentic_df) else 0.0

    macro_f1 = float(np.mean([authentic_f1_mean, forged_f1_mean]))
    overall_f1 = float(oof_df["best_f1"].mean()) if len(oof_df) else 0.0

    metrics = {
        "n_samples": int(len(oof_df)),
        "best_threshold": float(best_t),
        "macro_f1": macro_f1,
        "overall_f1": overall_f1,
        "macro_f1_std": float(oof_df["best_f1"].std() if len(oof_df) else 0.0),
        "thresholds": {str(k): float(v) for k, v in th2mean.items()},
        "zero_f1_ratio": zero_f1_ratio,
        "perfect_f1_ratio": perfect_f1_ratio,
        "forged_f1_mean": forged_f1_mean,
        "authentic_f1_mean": authentic_f1_mean,
        "forged_nonempty_ratio": forged_nonempty_ratio,
        "authentic_fp_ratio": authentic_fp_ratio,
        "best_postprocessing": {"min_area": int(best_min_area), "morph_kernel": int(best_morph_k)}
    }
    with open(out_dir / "metrics.json", "w") as f:
        json.dump(metrics, f, indent=2)

    run = {
        "experiment_id": exp_id,
        "date": datetime.now().date().isoformat(),
        "status": "completed",
        "cv": {"macro_f1": macro_f1},
        "artifacts": {"experiment_dir": str(out_dir)},
        "forged_nonempty_ratio": forged_nonempty_ratio,
        "authentic_fp_ratio": authentic_fp_ratio
    }
    with open(out_dir / "run.json", "w") as f:
        json.dump(run, f, indent=2)

    # å¼·åˆ¶åœæ­¢ï¼ˆé€€åŒ–è§£ã‚¬ãƒ¼ãƒ‰ï¼‰
    if forged_nonempty_ratio < config.MIN_FORGED_NONEMPTY_RATIO:
        raise SystemExit(f"âŒ forged_nonempty_ratio={forged_nonempty_ratio:.3f} < {config.MIN_FORGED_NONEMPTY_RATIO} â†’ å¼·åˆ¶åœæ­¢")
    if authentic_fp_ratio > config.MAX_AUTHENTIC_FP_RATIO:
        raise SystemExit(f"âŒ authentic_fp_ratio={authentic_fp_ratio:.3f} > {config.MAX_AUTHENTIC_FP_RATIO} â†’ å¼·åˆ¶åœæ­¢")
    return metrics
```

---

## 7. ğŸ”„ ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œãƒ–ãƒ­ãƒƒã‚¯ (Main Pipeline Block) â€” ç¾å ´æŒ‡æ®å®˜

- **`Config`ã®æŒ‡ç¤ºã‚’å¿ å®Ÿã«å®Ÿè¡Œ**
- **æ¨™æº–å…µå™¨ï¼ˆWeightedSampler/WeightedLossï¼‰ã‚’ã‚¹ã‚¤ãƒƒãƒã«å¿œã˜ã¦è‡ªå‹•è£…å‚™**
- **å…¨foldçµ‚äº†å¾Œã«å…¨ä½“é›†è¨ˆæˆæœç‰©ã‚’ç”Ÿæˆã™ã‚‹å‡¦ç†ã‚’å¿…ãšè¿½åŠ ã™ã‚‹ã“ã¨**

```python
from torch.utils.data import DataLoader, WeightedRandomSampler
from sklearn.model_selection import GroupKFold

def main():
    config = Config()
    logger = Logger(config.ARTIFACTS_DIR / 'train.log')
    logger.info(f"Experiment started: {config.EXP_ID}")
    logger.info(f"TRAINING_MODE: {config.TRAINING_MODE}")

    # Data
    df = prepare_dataframe(config)
    gkf = GroupKFold(n_splits=config.N_SPLITS)
    groups = df[config.GROUP_COL]

    for fold, (train_idx, val_idx) in enumerate(gkf.split(df, groups=groups)):
        if config.USE_FIRST_FOLD_ONLY and fold > 0:
            break

        logger.info(f"\n{'=' * 80}")
        logger.info(f"FOLD {fold+1}/{config.N_SPLITS}")
        logger.info(f"{'=' * 80}")

        train_df = df.iloc[train_idx].reset_index(drop=True)
        val_df = df.iloc[val_idx].reset_index(drop=True)
        logger.info(f"âœ“ Train: {len(train_df)}, Val: {len(val_df)}")

        train_ds = get_dataset(train_df, config, is_train=True)
        val_ds = get_dataset(val_df, config, is_train=False)

        # === DataLoaderã®æ§‹ç¯‰ï¼ˆæ¨™æº–å…µå™¨ï¼šWeightedSamplerï¼‰ ===
        train_sampler = None
        shuffle = True
        if config.TrainConfig.USE_WEIGHTED_SAMPLER:
            logger.info(f"âœ“ Using WeightedRandomSampler with forged_weight={config.TrainConfig.FORGED_SAMPLE_WEIGHT}")
            train_labels = train_df['is_forged'].values
            sample_weights = [config.TrainConfig.FORGED_SAMPLE_WEIGHT if label == 1 else 1.0 for label in train_labels]
            train_sampler = WeightedRandomSampler(torch.DoubleTensor(sample_weights), len(sample_weights))
            shuffle = False

        train_loader = DataLoader(train_ds, batch_size=config.TrainConfig.BATCH_SIZE, sampler=train_sampler, shuffle=shuffle, num_workers=0)
        val_loader = DataLoader(val_ds, batch_size=config.TrainConfig.BATCH_SIZE, shuffle=False, num_workers=0)

        # === ãƒ¢ãƒ‡ãƒ«ã¨æå¤±é–¢æ•°ã®æ§‹ç¯‰ï¼ˆæ¨™æº–å…µå™¨ï¼šWeightedLossï¼‰ ===
        model = build_model(config)
        params = sum(p.numel() for p in model.parameters())
        logger.info(f"âœ“ Model created with {params:,} parameters")

        if config.TrainConfig.USE_WEIGHTED_LOSS:
            logger.info(f"âœ“ Using WeightedBCEDiceLoss with pos_weight={config.TrainConfig.POS_WEIGHT}")
            criterion = WeightedBCEDiceLoss(pos_weight=config.TrainConfig.POS_WEIGHT)
        else:
            logger.info("âœ“ Using simple BCE loss (no weighting)")
            criterion = nn.BCELoss()

        optimizer = torch.optim.AdamW(model.parameters(), lr=config.TrainConfig.LEARNING_RATE, weight_decay=config.TrainConfig.WEIGHT_DECAY)

        # Train
        logger.info("\n" + "=" * 80)
        logger.info("TRAINING")
        logger.info("=" * 80)
        for epoch in range(config.TrainConfig.NUM_EPOCHS):
            loss = train_epoch(model, train_loader, optimizer, criterion, config.DEVICE)
            logger.info(f"Epoch {epoch+1}/{config.TrainConfig.NUM_EPOCHS} - Loss: {loss:.4f}")
            if (epoch + 1) % 1 == 0:
                torch.save(model.state_dict(), config.MODELS_DIR / f"model_fold{fold}_epoch{epoch+1}.pth")

        # Validation (oOF1)
        logger.info("\n" + "=" * 80)
        logger.info("VALIDATION (OOF, grid search)")
        logger.info("=" * 80)
        best_cfg, grid_results = validate_grid(
            model, val_loader,
            config.CONFIDENCE_THRESHOLDS_GRID,
            config.MIN_AREA_GRID,
            config.MORPH_KERNEL_SIZE_GRID,
            config.DEVICE, val_df
        )
        min_area, morph_k, th2mean, oof_rows = best_cfg
        best_t = max(th2mean, key=th2mean.get)
        logger.info(f"âœ“ Best PP: min_area={min_area}, morph_kernel={morph_k}, best_threshold={best_t:.3f}")

        # Save metrics + å¼·åˆ¶åœæ­¢ã‚¬ãƒ¼ãƒ‰
        # foldæˆæœç‰©ã¯ fold{n} ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸
        fold_dir = config.ARTIFACTS_DIR / f'fold{fold}'
        metrics = save_validation_artifacts(
            oof_rows, th2mean, fold_dir, config.EXP_ID,
            best_min_area=min_area, best_morph_k=morph_k, config=config
        )
        logger.info(f"âœ“ macro_f1={metrics['macro_f1']:.4f}, forged_nonempty_ratio={metrics['forged_nonempty_ratio']:.3f}, authentic_fp_ratio={metrics['authentic_fp_ratio']:.3f}")

        # å®Œäº†
        torch.save(model.state_dict(), config.MODELS_DIR / f"model_fold{fold}_final.pth")
        logger.info("\n" + "=" * 80)
        logger.info("FOLD COMPLETE")
        logger.info("=" * 80)

    # === å…¨ä½“é›†è¨ˆæˆæœç‰©ç”Ÿæˆ ===
    aggregate_oof_all_and_metrics(config)

if __name__ == "__main__":
    main()
```

---

## 8. ğŸš€ å®Ÿè¡Œãƒˆãƒªã‚¬ãƒ¼ãƒ–ãƒ­ãƒƒã‚¯ (Execution Trigger Block)

```python
if __name__ == "__main__":
    main()
```

---

## 9. ğŸ“Š ç’°å¢ƒãƒãƒ¼ã‚¸ãƒ§ãƒ³è¨˜éŒ²ãƒ–ãƒ­ãƒƒã‚¯ (Environment Version Logging Block)

- 2ç« LoggeråˆæœŸåŒ–ã§æ—¢ã«å‡ºåŠ›æ¸ˆã¿ã€‚è¿½åŠ ã§å¿…è¦ãªã‚‰é–¢æ•°åŒ–ã—ã¦å†åˆ©ç”¨

---

## 10. ğŸ§ª æå‡ºè£œåŠ©ï¼ˆä»»æ„ï¼‰: RLEã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ»æå‡ºå½¢å¼æ¤œè¨¼ï¼ˆOOFç¢ºç«‹å¾Œã«å°å…¥ï¼‰

- åˆ—ãƒ¡ã‚¸ãƒ£ãƒ¼/1-indexed/JSONé…åˆ—å½¢å¼

```python
def rle_encode(mask):
    mask = (mask > 0).astype(np.uint8)
    if mask.sum() == 0:
        return "authentic"
    pixels = mask.T.flatten()
    runs = []
    prev = 0
    pos = 0
    for i, p in enumerate(pixels):
        if p != prev:
            if prev == 1:
                runs.extend([pos + 1, i - pos])
            if p == 1:
                pos = i
            prev = p
    if prev == 1:
        runs.extend([pos + 1, len(pixels) - pos])
    return json.dumps([int(x) for x in runs])
```


## 11. ğŸ—‚ï¸ æˆæœç‰©é…ç½®ãƒ»å‘½åè¦å‰‡ï¼ˆfoldã”ã¨ä¿å­˜ï¼‹å…¨ä½“é›†è¨ˆä¿å­˜ã®æ–¹é‡ï¼‰

- æˆæœç‰©ã¯å¿…ãšä»¥ä¸‹ã«ä¿å­˜ã—ã¦ãã ã•ã„ï¼ˆä½™è¨ˆãªä¸Šä½éšå±¤ã¯ä½œã‚‰ãªã„ï¼‰
    - ãƒ­ãƒ¼ã‚«ãƒ«: `experiments/<exp_id>-artifacts/`
    - Kaggle: `/kaggle/working/<exp_id>-artifacts/`
    **Kaggleæå‡ºæ™‚ã¯ submission.csv ã‚’ `/kaggle/working/submission.csv`ï¼ˆoutputç›´ä¸‹ï¼‰ã«ã‚‚ã‚³ãƒ”ãƒ¼ã—ã¦ãã ã•ã„ã€‚Kaggleæå‡ºUIã¯ outputç›´ä¸‹ã®ã¿æå‡ºå¯¾è±¡ã¨ã—ã¦èªè­˜ã™ã‚‹ãŸã‚ã€ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯è‡ªå‹•æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã€‚**
- foldã”ã¨ã®æˆæœç‰©ï¼ˆmetrics.json, oof.csv, run.jsonç­‰ï¼‰ã¯ `fold0/`, `fold1/`, ... ã®ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ã—ã¾ã™ï¼ˆå˜ä¸€foldã§ã‚‚ `fold0/` ã‚’ä½¿ç”¨ï¼‰ã€‚
- å…¨ä½“é›†è¨ˆæˆæœç‰©ï¼ˆsubmission.csv, oof_all.csv, overall_metrics.json, validate_summary.csv, train.log ç­‰ï¼‰ã¯ `*-artifacts/` ç›´ä¸‹ã«å¿…ãšä¿å­˜ã—ã¦ãã ã•ã„ã€‚
- å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¯ `*-artifacts/models/` é…ä¸‹ã«ä¿å­˜ã—ã€ãƒ•ã‚¡ã‚¤ãƒ«åã¯ `decoder_fold{n}_final.pth` ç­‰ã€foldãŒè­˜åˆ¥ã§ãã‚‹å‘½åã«ã—ã¦ãã ã•ã„ã€‚
- ã“ã‚Œã«ã‚ˆã‚Šã€validate.pyã‚„æ¤œè¨¼NotebookãŒå…¨ä½“é›†è¨ˆæˆæœç‰©ã‚’è‡ªå‹•æ¤œå‡ºãƒ»é›†è¨ˆã§ãã¾ã™ã€‚
- **è¤‡æ•°foldï¼ˆCVï¼‰æ™‚ã¯ã€Œfoldã”ã¨æˆæœç‰©ã€ã¨ã€Œå…¨ä½“é›†è¨ˆæˆæœç‰©ã€ã®ä¸¡æ–¹ã‚’å¿…ãšä¿å­˜ãƒ»ç®¡ç†ã™ã‚‹ã“ã¨ã€‚**

ä¾‹ï¼ˆ5-foldã®æƒ³å®šï¼‰:

```
<exp_id>-artifacts/
â”œâ”€ fold0/
â”‚  â”œâ”€ metrics.json
â”‚  â”œâ”€ oof.csv
â”‚  â””â”€ run.json
â”œâ”€ fold1/
â”‚  â””â”€ ...
â”œâ”€ fold2/
â”‚  â””â”€ ...
â”œâ”€ fold3/
â”‚  â””â”€ ...
â”œâ”€ fold4/
â”‚  â””â”€ ...
â”œâ”€ models/
â”‚  â”œâ”€ decoder_fold0_final.pth
â”‚  â”œâ”€ decoder_fold1_final.pth
â”‚  â””â”€ ...
â”œâ”€ oof_all.csv
â”œâ”€ overall_metrics.json
â”œâ”€ validate_summary.csv
â”œâ”€ submission.csv
â””â”€ train.log
```

---

## 12. ğŸ“ ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] foldã”ã¨æˆæœç‰©ï¼ˆmetrics.json, oof.csv, run.jsonç­‰ï¼‰ãŒæƒã£ã¦ã„ã‚‹
- [ ] å…¨ä½“é›†è¨ˆæˆæœç‰©ï¼ˆoverall_metrics.json, oof_all.csv, validate_summary.csvç­‰ï¼‰ãŒæƒã£ã¦ã„ã‚‹
- [ ] run.json, report.md, README.md ã‚‚æ›´æ–°æ¸ˆã¿

---

## ä»˜éŒ²A: ä»•æ§˜ã®è¦ç‚¹ï¼ˆå·®åˆ†ã‚µãƒãƒªï¼‰

- **æœ€ä¸Šä½æˆ¦ç•¥ãƒ•ãƒ©ã‚° `TRAINING_MODE`** ã§å­¦ç¿’æ–¹å¼åˆ‡ã‚Šæ›¿ãˆï¼ˆpixel_based/feature_basedï¼‰
- **æ¨™æº–å…µå™¨ï¼ˆWeightedSampler/WeightedLossï¼‰ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆON**
- Datasetã¯ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼ï¼ˆ`get_dataset`ï¼‰ã§è‡ªå‹•ç”Ÿæˆ
- ãƒ¢ãƒ‡ãƒ«ã‚‚ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼ï¼ˆ`build_model`ï¼‰ã§è‡ªå‹•ç”Ÿæˆ
- æ¤œè¨¼ã¯validate_gridï¼ˆVal Losséæ¡ç”¨ï¼‰ã€‚æŒ‡æ¨™ã¯macro_f1/forged_nonempty_ratio/authentic_fp_ratio
- é€€åŒ–è§£ã‚¬ãƒ¼ãƒ‰ã¯å¼·åˆ¶åœæ­¢ï¼ˆæˆæœç‰©ã‚’æ®‹ã•ãšrunçµ‚äº†ï¼‰

---

## ä»˜éŒ²B: ä½¿ç”¨ä¾‹

### EXP003Tï¼ˆDINOv2ç‰¹å¾´é‡ãƒ™ãƒ¼ã‚¹ï¼‰ã§ä½¿ã†å ´åˆ

```python
# Configã§ä»¥ä¸‹ã‚’è¨­å®š
TRAINING_MODE = "feature_based"
FeatureConfig.FEATURE_DIR = Path('/kaggle/input/exp003t-dino-v2-features')
FeatureConfig.FEATURE_DIM = 768
FeatureConfig.DECODER_TYPE = "SimpleDecoder"
```

### EXP002Tï¼ˆãƒ”ã‚¯ã‚»ãƒ«ãƒ™ãƒ¼ã‚¹ãƒ»U-Netï¼‰ã§ä½¿ã†å ´åˆ

```python
# Configã§ä»¥ä¸‹ã‚’è¨­å®š
TRAINING_MODE = "pixel_based"
PixelConfig.MODEL_TYPE = "FastUNet"
PixelConfig.IMAGE_SIZE = 256
PixelConfig.AUGMENTATIONS = "medium"
```

### ğŸ§ª ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¹ã‚­ãƒ¼ãƒï¼ˆmetrics.json / run.jsonï¼‰

æŒ‡æ¨™ã®å‘½åã‚’ä»¥ä¸‹ã«çµ±ä¸€ã—ã€`macro_f1` ã®æ„å‘³ã®æ··ä¹±ï¼ˆforged-onlyå¹³å‡ã¨ã®æ··åŒï¼‰ã‚’é¿ã‘ã‚‹ã€‚

| ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ | å®šç¾© | å‚™è€ƒ |
|-----------|------|------|
| metric_version | ã‚¹ã‚­ãƒ¼ãƒãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€‚`v1` ç¾è¡Œ, `v0` æ—§(forced-only) | validateã§åˆ†å² |
| mean_f1_forged | forgedç”»åƒã«å¯¾ã™ã‚‹å¹³å‡F1 | æ—§ `macro_f1` (v0) ç›¸å½“ |
| f1_authentic | authenticç”»åƒã®F1 (ç©ºã‚’æ­£ã—ãç©ºã¨å‡ºã›ã°1, éç©ºãªã‚‰0) | `1 - authentic_fp_ratio` ã¨åŒç¾© |
| macro_f1 | (mean_f1_forged + f1_authentic) / 2 | ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®ä¸»è»¸ |
| forged_nonempty_ratio | forgedç”»åƒã§éç©ºäºˆæ¸¬ã—ãŸå‰²åˆ | æ¤œå‡ºç‡ |
| authentic_fp_ratio | authenticç”»åƒã§éç©ºäºˆæ¸¬ã—ãŸå‰²åˆ | èª¤æ¤œå‡ºç‡ (ä½ã„ã»ã©è‰¯ã„) |
| best_threshold | ãƒã‚¹ã‚¯äºŒå€¤åŒ–ã«ç”¨ã„ãŸæœ€è‰¯é–¾å€¤ | ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒæ™‚ |
| best_postprocessing | æœ€è‰¯å¾Œå‡¦ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | {min_area, morph_kernel, ...} |
| created_at | ç”Ÿæˆæ—¥æ™‚ | ISO8601 |

`overall_metrics.json` ã§ã¯ä¸Šè¿°ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã® *_mean / *_std ã‚’ä»˜åŠ ã—ã€foldé…åˆ—ã«å„foldã®metrics.jsonå†…å®¹ã‚’ãã®ã¾ã¾æ ¼ç´ã™ã‚‹ã€‚

### ğŸ”„ ãƒ¬ã‚¬ã‚·ãƒ¼äº’æ› (v0 â†’ v1 ç§»è¡Œ)

æ—§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ(v0)ã§ã¯ `macro_f1` ãŒ forged-only å¹³å‡ã‚’æŒ‡ã—ã¦ã„ã‚‹ã€‚validateå´ã§ä»¥ä¸‹ãƒ­ã‚¸ãƒƒã‚¯ã‚’é©ç”¨ã—è‡ªå‹•è£œå®Œã™ã‚‹:
1. `metric_version` ãŒãªã„ or `v0` â†’ `mean_f1_forged = macro_f1`
2. `f1_authentic` ãŒç„¡ã‘ã‚Œã° `authentic_fp_ratio` ãŒã‚ã‚Œã° `f1_authentic = 1 - authentic_fp_ratio`ã€ç„¡ã‘ã‚Œã° `null`ã€‚
3. `macro_f1` ã‚’å†è¨ˆç®—ã§ãã‚Œã°å†è¨ˆç®—ã€ã§ããªã‘ã‚Œã° forged-only ã‚’æš«å®šå€¤ã¨ã— `macro_f1_legacy = macro_f1` ã‚’å†…éƒ¨åˆ©ç”¨ã€‚

### âœ… validate_summary.csv è¿½åŠ åˆ—

`validate_summary.csv` ã«ã¯å°‘ãªãã¨ã‚‚ä»¥ä¸‹åˆ—ã‚’å«ã‚ã‚‹:
```
fold, macro_f1, mean_f1_forged, f1_authentic,
forged_nonempty_ratio, authentic_fp_ratio
```

ã“ã‚Œã«ã‚ˆã‚Šæ¨ªæ–­æ¯”è¼ƒãƒ»å¥å…¨æ€§åˆ¤å®šãƒ»æ¨ç§»åˆ†æãŒå®¹æ˜“ã«ãªã‚‹ã€‚